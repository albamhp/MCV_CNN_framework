# Problem type
problem_type                : 'classification' # Option: ['segmentation','classification']

# Model
model_type                  : 'oscarnet'   # Options: ['DenseNetFCN', 'FCN8']

### load/store options
resume_experiment           : False
pretrained_model            : 'None'  # 'None': from scratch, 'basic': pretraned from imagenet, 'custom': personal model
input_model_path            : null  # Path and pretrained file to load [None uses experiment path and model name by default]
load_weight_only            : True  # Recomended true, loads only weights and parameters

### Save options
save_weight_only            : True  # Recomended true, stores only weights and parameters
model_name                  : 'oscarnet'  # Name of the model to store
output_model_path           : null  # Path to store the model using model_name [None uses the default experiment path]
basic_models_path           : null

# Loss type
loss_type                   : 'cross_entropy_classification' # options: ['cross_entropy_segmentation','focal_segmentation']
normalize_loss              : True

# General parameters

train_samples               : -1
#-1 uses all the data available inside the dataset files
valid_samples               : -1
#-1 uses all the data available inside the dataset files
test_samples                : -1
#-1 uses all the data available inside the dataset files
train_batch_size            : 40
valid_batch_size            : 40
test_batch_size             : 40
train                       : True
validation                  : True
test                        : True # Calculate metrics on test giving the gt
predict_test                : True # True when you want to generate predictions from test, doesn't need gt
predict_path_output         : null # null uses the default output in the experiment folder /predictions

# Image properties
size_image_test             : null
resize_image_train          : !!python/tuple [224, 224]
resize_image_valid          : !!python/tuple [224, 224]
resize_image_test           : !!python/tuple [224, 224]
crop_train                  : null
grayscale                   : False #Use this option to convert to rgb a grascale dataset

# Dataset properties

train_dataset_path          : '/home/mcv/datasets/M5/classification/BelgiumTSC/train'
valid_dataset_path          : '/home/mcv/datasets/M5/classification/BelgiumTSC/valid'
test_dataset_path           : '/home/mcv/datasets/M5/classification/BelgiumTSC/test'
train_images_txt            : null
train_gt_txt                : null
valid_images_txt            : null
valid_gt_txt                : null
test_images_txt             : null
test_gt_txt                 : null

labels                      : null
map_labels                  : null

num_classes                 : 62
shuffle                     : True
void_class                  : 255 #void id or value on the image

# Training
epochs                      : 50 #Max number of epochs
initial_epoch               : 1 #Defines the starting epoch number
valid_samples_epoch         : -1 # Number of validation images used to validate an epoch
is_training                 : True
    ### Optimizer ###
optimizer                   : 'SGD'
momentum1                   : 0.9
momentum2                   : 0.9
learning_rate               : 1.0e-3
learning_rate_bias          : 1.0e-3
weight_decay                : 5.0e-4
    ### Scheduler
scheduler                   : 'MultiStep' #['ReduceLROnPlateau','Step','MultiStep','Exponential', None]
decay                       : 0.1 #Learnng rate decay to apply (lr*decay)
sched_patience              : 5 # ReduceLROnPlateau option: epoch patience without loss change until a lr decrement
step_size                   : 20 #Step option: epoch counter to decrease lr
milestone                   : !!python/tuple [10] #MultiStep option: define different milestones (epochs) to decrease lr
    ### Save criteria
save_condition              : 'f1_score' # ['always','(x)_loss','(x)_mAcc','(x)_mIoU'] x : valid or train_loss
    ### Early Stopping
early_stopping              : False
stop_condition              : 'f1_score' # [(x)_loss','(x)_mAcc','(x)_mIoU'] x : valid or train_loss
patience                    : 5

# Image preprocess
rescale                     : 1.
mean                        : !!python/tuple [127.5,127.5,127.5] #[104.00698793, 116.66876762, 122.67891434] #[103.939, 116.779, 123.68] #[0.28689553, 0.32513301, 0.28389176] #[0.37296272, 0.37296272, 0.37296272]
std                         : !!python/tuple [1.,1.,1.] #[0.18696375, 0.19017339, 0.18720214]#[0.21090189, 0.21090189, 0.21090189]

# Data augmentation
hflips                      : False
random_dist                 : False  # Activate random distortions to the input image [brightness, contrast, saturation]

color_map                   : null
num_images                  : null